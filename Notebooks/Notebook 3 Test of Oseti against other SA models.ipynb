{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Test of Oseti against other SA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import oseti\n",
    "import statistics\n",
    "import nltk\n",
    "#nltk.download('all') #runs first time only\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Here, the Oseti library is used in a slightly modified form. Oseti is dependent on the MeCab tokenization ,however, the current version of Oseti was not adjusted for the updated MeCab. The code may be adjusted for MeCab, but in this notebook we use Neolog Dictionary with Janome as a tokenizer. In practice, this has almost no effect for the sentiment score. In the analysis of the corpora, pure Oseti was used with minor adjustments for compatibility with a newer MeCab version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "analyzer = oseti.Analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oseti-dictionary based sentiment analysis vs rule-based VADER\n",
    "Here, we juxtapose the two approaches. Oseti sentiment analyzer has a built-in sentence tokenizer, while VADER demands usage of a particular tokenizers (like one in the NLTK package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"text samplings\\\\direct speech sampling JA.txt\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "sampling_ja = text.split(\"\\n\")\n",
    "\n",
    "with open (\"text samplings\\\\direct speech sampling EN.txt\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "sampling_en = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of samplings\n",
    "no_sampling_ja = len(sampling_ja)\n",
    "no_sampling_en = len(sampling_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oseti results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oseti_sentiment = [statistics.mean(analyzer.analyze(sent)) for sent in sampling_ja]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sentiment = [sia.polarity_scores(sent)['compound'] for sent in sampling_en]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-finetuned-japanese-sentiment\n",
    "Training dataset: Amazon Reviews\\\n",
    "No.: 20000 reviews\\\n",
    "Link: https://huggingface.co/christian-phu/bert-finetuned-japanese-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "100%|██████████| 159/159 [01:07<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# model needs the following dependencies:\n",
    "#!pip install fugashi\n",
    "#!pip install unidic_lite\n",
    "\n",
    "\n",
    "sentiment_analyzer = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=\"christian-phu/bert-finetuned-japanese-sentiment\"\n",
    "        )\n",
    "bert_sentiment = []\n",
    "for sent in tqdm(sampling_ja):\n",
    "    result = sentiment_analyzer(sent)[0]\n",
    "    label_to_score = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "    compound_score = label_to_score[result['label']] * result['score']\n",
    "    bert_sentiment.append(compound_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### japanese-sentiment-analysis\n",
    "Training dataset: Corporate financial reports\\\n",
    "No.: 200 reports (6,119 sentences)\\\n",
    "Link: https://huggingface.co/jarvisx17/japanese-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "100%|██████████| 159/159 [00:55<00:00,  2.84it/s]\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer_jarv = pipeline(\"sentiment-analysis\", model=\"jarvisx17/japanese-sentiment-analysis\")\n",
    "jarv_sentiment = []\n",
    "for sent in tqdm(sampling_ja):\n",
    "    result = sentiment_analyzer_jarv(sent)[0]\n",
    "    label_to_score = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "    compound_score = label_to_score[result['label']] * result['score']\n",
    "    jarv_sentiment.append(compound_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Japanese Stock Comment Sentiment Model\n",
    "Training dataset: Comments and discussions related to Japanese stocks\\\n",
    "No.: Not clarified\\\n",
    "Link: https://huggingface.co/c299m/japanese_stock_sentiment\\\n",
    "\\\n",
    "\\\n",
    "This model is inapplicable for SA, as it estimates only market trends in two categories: \"bullish\" and \"bearish\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finance-sentiment-ja-base\n",
    "Training dataset: Japanese financial news\\\n",
    "No.: ≈5,000 sentences/phrases\\\n",
    "Link: https://huggingface.co/bardsai/finance-sentiment-ja-base\\\n",
    "\\\n",
    "The model is unoperabable as in the majority of cases it outputs neutral sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "100%|██████████| 159/159 [00:51<00:00,  3.10it/s]\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer_bardsai = pipeline(\"sentiment-analysis\", model=\"bardsai/finance-sentiment-ja-base\")\n",
    "bardsai_sentiment = []\n",
    "for sent in tqdm(sampling_ja):\n",
    "    result = sentiment_analyzer_bardsai(sent)[0]\n",
    "    label_to_score = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "    compound_score = label_to_score[result['label']] * result['score']\n",
    "    bardsai_sentiment.append(compound_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_df = pd.DataFrame({\"Oseti\": oseti_sentiment, \"VADER\": vader_sentiment, \"bert-finetuned-japanese-sentiment\": bert_sentiment,\n",
    "                               \"japanese-sentiment-analysis\": jarv_sentiment,\"finance-sentiment-ja-base\": bardsai_sentiment})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_df.to_csv(\"Models Overview Dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oseti</th>\n",
       "      <th>VADER</th>\n",
       "      <th>bert-finetuned-japanese-sentiment</th>\n",
       "      <th>japanese-sentiment-analysis</th>\n",
       "      <th>finance-sentiment-ja-base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.058192</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.374328</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.010143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.517422</td>\n",
       "      <td>0.384876</td>\n",
       "      <td>0.646258</td>\n",
       "      <td>0.923552</td>\n",
       "      <td>0.145701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.928700</td>\n",
       "      <td>-0.997148</td>\n",
       "      <td>-0.999939</td>\n",
       "      <td>-0.999920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.064400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.988994</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652621</td>\n",
       "      <td>0.988310</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>0.984478</td>\n",
       "      <td>0.999605</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900100</td>\n",
       "      <td>0.999272</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Oseti       VADER  bert-finetuned-japanese-sentiment  \\\n",
       "count  159.000000  159.000000                         159.000000   \n",
       "mean     0.058192    0.002313                           0.374328   \n",
       "std      0.517422    0.384876                           0.646258   \n",
       "min     -1.000000   -0.928700                          -0.997148   \n",
       "25%      0.000000   -0.064400                           0.000000   \n",
       "50%      0.000000    0.000000                           0.652621   \n",
       "75%      0.000000    0.137800                           0.984478   \n",
       "max      1.000000    0.900100                           0.999272   \n",
       "\n",
       "       japanese-sentiment-analysis  finance-sentiment-ja-base  \n",
       "count                   159.000000                 159.000000  \n",
       "mean                      0.314734                   0.010143  \n",
       "std                       0.923552                   0.145701  \n",
       "min                      -0.999939                  -0.999920  \n",
       "25%                      -0.988994                   0.000000  \n",
       "50%                       0.988310                   0.000000  \n",
       "75%                       0.999605                   0.000000  \n",
       "max                       0.999955                   0.999010  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformer models for Japanese sentiment analysis did not demonstrate a strong rationale for their advantage over the simplistic, dictionary-based method used by Oseti.\n",
    "\n",
    "1. They do not provide a direct interface for calculating sentiment intensity. Instead, intensity scores are indirectly inferred from the model’s confidence (probability) in classifying a sentence as positive, negative, or neutral.\n",
    "\n",
    "2. Among the four documented models, only two are operational. The Japanese Stock Comment Sentiment Model is not suitable for this study, as its sentiment classes (\"bearish\" and \"bullish\") do not align with the required categories. The finance-sentiment-ja-base model tends to classify most sentences as neutral when applied to samples from the Atomic Bomb Literature corpus.\n",
    "\n",
    "3. The transformer models did not demonstrate a meaningfully stronger correlation with the VADER model, nor among themselves.\n",
    "\n",
    "4. Given the advantages of rule-based models like VADER—particularly their transparency and traceability—we consider VADER a reliable reference point. When comparing against this benchmark, Oseti shows significantly better alignment. Although finance-sentiment-ja-base produced slightly higher precision, recall, and F1 scores, 155 out of its 157 predictions were classified as neutral, limiting its practical usefulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oseti</th>\n",
       "      <th>VADER</th>\n",
       "      <th>bert-finetuned-japanese-sentiment</th>\n",
       "      <th>japanese-sentiment-analysis</th>\n",
       "      <th>finance-sentiment-ja-base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Oseti</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.357845</td>\n",
       "      <td>0.268596</td>\n",
       "      <td>0.271637</td>\n",
       "      <td>0.155789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VADER</th>\n",
       "      <td>0.357845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.345126</td>\n",
       "      <td>0.381054</td>\n",
       "      <td>0.153501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-finetuned-japanese-sentiment</th>\n",
       "      <td>0.268596</td>\n",
       "      <td>0.345126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.329962</td>\n",
       "      <td>0.000454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese-sentiment-analysis</th>\n",
       "      <td>0.271637</td>\n",
       "      <td>0.381054</td>\n",
       "      <td>0.329962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.146033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finance-sentiment-ja-base</th>\n",
       "      <td>0.155789</td>\n",
       "      <td>0.153501</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.146033</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Oseti     VADER  \\\n",
       "Oseti                              1.000000  0.357845   \n",
       "VADER                              0.357845  1.000000   \n",
       "bert-finetuned-japanese-sentiment  0.268596  0.345126   \n",
       "japanese-sentiment-analysis        0.271637  0.381054   \n",
       "finance-sentiment-ja-base          0.155789  0.153501   \n",
       "\n",
       "                                   bert-finetuned-japanese-sentiment  \\\n",
       "Oseti                                                       0.268596   \n",
       "VADER                                                       0.345126   \n",
       "bert-finetuned-japanese-sentiment                           1.000000   \n",
       "japanese-sentiment-analysis                                 0.329962   \n",
       "finance-sentiment-ja-base                                   0.000454   \n",
       "\n",
       "                                   japanese-sentiment-analysis  \\\n",
       "Oseti                                                 0.271637   \n",
       "VADER                                                 0.381054   \n",
       "bert-finetuned-japanese-sentiment                     0.329962   \n",
       "japanese-sentiment-analysis                           1.000000   \n",
       "finance-sentiment-ja-base                             0.146033   \n",
       "\n",
       "                                   finance-sentiment-ja-base  \n",
       "Oseti                                               0.155789  \n",
       "VADER                                               0.153501  \n",
       "bert-finetuned-japanese-sentiment                   0.000454  \n",
       "japanese-sentiment-analysis                         0.146033  \n",
       "finance-sentiment-ja-base                           1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Oseti</th>\n",
       "      <th>bert-finetuned-japanese-sentiment</th>\n",
       "      <th>japanese-sentiment-analysis</th>\n",
       "      <th>finance-sentiment-ja-base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.584939</td>\n",
       "      <td>0.360627</td>\n",
       "      <td>0.230748</td>\n",
       "      <td>0.657199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.591195</td>\n",
       "      <td>0.345912</td>\n",
       "      <td>0.408805</td>\n",
       "      <td>0.452830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.577118</td>\n",
       "      <td>0.328412</td>\n",
       "      <td>0.289929</td>\n",
       "      <td>0.305955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Oseti  bert-finetuned-japanese-sentiment  \\\n",
       "0  Precision  0.584939                           0.360627   \n",
       "1     Recall  0.591195                           0.345912   \n",
       "2         F1  0.577118                           0.328412   \n",
       "\n",
       "   japanese-sentiment-analysis  finance-sentiment-ja-base  \n",
       "0                     0.230748                   0.657199  \n",
       "1                     0.408805                   0.452830  \n",
       "2                     0.289929                   0.305955  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def transform_sentiment(input_scores):\n",
    "    \"\"\"sent > 0 -> 1; sent < 0 -> -1; sent = 0 -> 0\"\"\"\n",
    "    transformed_sentiment = [1 if score > 0 else (-1 if score < 0 else 0) for score in input_scores]\n",
    "    return transformed_sentiment\n",
    "\n",
    "y_vader = transform_sentiment(vader_sentiment)  \n",
    "y_oseti = transform_sentiment(oseti_s)\n",
    "y_bert = transform_sentiment(bert_sentiment)\n",
    "y_jarv = transform_sentiment(jarv_sentiment)\n",
    "y_bardsai = transform_sentiment(bardsai_sentiment)\n",
    "\n",
    "def get_metrics(true_values, predicted_values):\n",
    "    \"\"\"Calculates precision, recall, and F1 score.\"\"\"\n",
    "    precision = precision_score(true_values, predicted_values, average='weighted')  # Using 'weighted' for multi-class\n",
    "    recall = recall_score(true_values, predicted_values, average='weighted')\n",
    "    f1 = f1_score(true_values, predicted_values, average='weighted')\n",
    "    return [precision, recall, f1]\n",
    "\n",
    "\n",
    "oseti_metrics = get_metrics(y_vader, y_oseti)\n",
    "bert_metrics = get_metrics(y_vader, y_bert)\n",
    "jarv_metrics = get_metrics(y_vader, y_jarv)\n",
    "bardsai_metrics = get_metrics(y_vader, y_bardsai)\n",
    "\n",
    "metrics_df = pd.DataFrame({\"Metric\": [\"Precision\", \"Recall\", \"F1\"], \"Oseti\": oseti_metrics,\n",
    "        \"bert-finetuned-japanese-sentiment\": bert_metrics, \"japanese-sentiment-analysis\": jarv_metrics,\n",
    "        \"finance-sentiment-ja-base\": bardsai_metrics})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(\"Models against VADER tests.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmean\u001b[49m([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "from statistics import mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
